{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5gSDU0Lmdpc0"
      },
      "source": [
        "# Repo Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "owAWoTuUdpc-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05a682c8-9a42-4ff8-8eaf-36cb2eae076a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'TalkingAvatar'...\n",
            "remote: Enumerating objects: 34, done.\u001b[K\n",
            "remote: Counting objects: 100% (34/34), done.\u001b[K\n",
            "remote: Compressing objects: 100% (29/29), done.\u001b[K\n",
            "remote: Total 34 (delta 2), reused 30 (delta 2), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (34/34), 107.59 KiB | 816.00 KiB/s, done.\n",
            "Resolving deltas: 100% (2/2), done.\n",
            "/content/TalkingAvatar\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/Drwaish/TalkingAvatar.git\n",
        "%cd TalkingAvatar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RDA9KU5ZaIlv",
        "outputId": "68c54135-eefb-49fd-ef17-b0ebf60f23fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 1)) (0.19.3)\n",
            "Collecting python_speech_features (from -r requirements.txt (line 2))\n",
            "  Downloading python_speech_features-0.6.tar.gz (5.6 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pyworld (from -r requirements.txt (line 3))\n",
            "  Downloading pyworld-0.3.4.tar.gz (251 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m252.0/252.0 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 4)) (6.0.1)\n",
            "Collecting pytorch-lightning (from -r requirements.txt (line 5))\n",
            "  Downloading pytorch_lightning-2.1.0-py3-none-any.whl (774 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m774.6/774.6 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: imageio in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 6)) (2.31.6)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 7)) (1.11.3)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 9)) (4.8.0.76)\n",
            "Collecting openai (from -r requirements.txt (line 10))\n",
            "  Downloading openai-0.28.1-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.0/77.0 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting gradio (from -r requirements.txt (line 11))\n",
            "  Downloading gradio-4.0.2-py3-none-any.whl (25.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m25.3/25.3 MB\u001b[0m \u001b[31m60.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting gTTS (from -r requirements.txt (line 12))\n",
            "  Downloading gTTS-2.4.0-py3-none-any.whl (29 kB)\n",
            "Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image->-r requirements.txt (line 1)) (1.23.5)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image->-r requirements.txt (line 1)) (3.2)\n",
            "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image->-r requirements.txt (line 1)) (9.4.0)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image->-r requirements.txt (line 1)) (2023.9.26)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->-r requirements.txt (line 1)) (1.4.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image->-r requirements.txt (line 1)) (23.2)\n",
            "Requirement already satisfied: cython>=0.24 in /usr/local/lib/python3.10/dist-packages (from pyworld->-r requirements.txt (line 3)) (3.0.4)\n",
            "Requirement already satisfied: torch>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning->-r requirements.txt (line 5)) (2.1.0+cu118)\n",
            "Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning->-r requirements.txt (line 5)) (4.66.1)\n",
            "Requirement already satisfied: fsspec[http]>2021.06.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning->-r requirements.txt (line 5)) (2023.6.0)\n",
            "Collecting torchmetrics>=0.7.0 (from pytorch-lightning->-r requirements.txt (line 5))\n",
            "  Downloading torchmetrics-1.2.0-py3-none-any.whl (805 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m805.2/805.2 kB\u001b[0m \u001b[31m68.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning->-r requirements.txt (line 5)) (4.5.0)\n",
            "Collecting lightning-utilities>=0.8.0 (from pytorch-lightning->-r requirements.txt (line 5))\n",
            "  Downloading lightning_utilities-0.9.0-py3-none-any.whl (23 kB)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai->-r requirements.txt (line 10)) (2.31.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai->-r requirements.txt (line 10)) (3.8.6)\n",
            "Collecting aiofiles<24.0,>=22.0 (from gradio->-r requirements.txt (line 11))\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: altair<6.0,>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 11)) (4.2.2)\n",
            "Collecting fastapi (from gradio->-r requirements.txt (line 11))\n",
            "  Downloading fastapi-0.104.1-py3-none-any.whl (92 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.9/92.9 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ffmpy (from gradio->-r requirements.txt (line 11))\n",
            "  Downloading ffmpy-0.3.1.tar.gz (5.5 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting gradio-client==0.7.0 (from gradio->-r requirements.txt (line 11))\n",
            "  Downloading gradio_client-0.7.0-py3-none-any.whl (302 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.7/302.7 kB\u001b[0m \u001b[31m39.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httpx (from gradio->-r requirements.txt (line 11))\n",
            "  Downloading httpx-0.25.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.7/75.7 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting huggingface-hub>=0.14.0 (from gradio->-r requirements.txt (line 11))\n",
            "  Downloading huggingface_hub-0.18.0-py3-none-any.whl (301 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.0/302.0 kB\u001b[0m \u001b[31m38.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 11)) (6.1.0)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 11)) (3.1.2)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 11)) (2.1.3)\n",
            "Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 11)) (3.7.1)\n",
            "Collecting orjson~=3.0 (from gradio->-r requirements.txt (line 11))\n",
            "  Downloading orjson-3.9.10-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (138 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.7/138.7 kB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 11)) (1.5.3)\n",
            "Collecting pydantic>=2.0 (from gradio->-r requirements.txt (line 11))\n",
            "  Downloading pydantic-2.4.2-py3-none-any.whl (395 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m395.8/395.8 kB\u001b[0m \u001b[31m49.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pydub (from gradio->-r requirements.txt (line 11))\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Collecting python-multipart (from gradio->-r requirements.txt (line 11))\n",
            "  Downloading python_multipart-0.0.6-py3-none-any.whl (45 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.7/45.7 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting semantic-version~=2.0 (from gradio->-r requirements.txt (line 11))\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Collecting tomlkit==0.12.0 (from gradio->-r requirements.txt (line 11))\n",
            "  Downloading tomlkit-0.12.0-py3-none-any.whl (37 kB)\n",
            "Requirement already satisfied: typer[all]<1.0,>=0.9 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 11)) (0.9.0)\n",
            "Collecting uvicorn>=0.14.0 (from gradio->-r requirements.txt (line 11))\n",
            "  Downloading uvicorn-0.23.2-py3-none-any.whl (59 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.5/59.5 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting websockets<12.0,>=10.0 (from gradio->-r requirements.txt (line 11))\n",
            "  Downloading websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: click<8.2,>=7.1 in /usr/local/lib/python3.10/dist-packages (from gTTS->-r requirements.txt (line 12)) (8.1.7)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio->-r requirements.txt (line 11)) (0.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio->-r requirements.txt (line 11)) (4.19.1)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio->-r requirements.txt (line 11)) (0.12.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai->-r requirements.txt (line 10)) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai->-r requirements.txt (line 10)) (3.3.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai->-r requirements.txt (line 10)) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai->-r requirements.txt (line 10)) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai->-r requirements.txt (line 10)) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai->-r requirements.txt (line 10)) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai->-r requirements.txt (line 10)) (1.3.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.14.0->gradio->-r requirements.txt (line 11)) (3.12.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio->-r requirements.txt (line 11)) (1.1.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio->-r requirements.txt (line 11)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio->-r requirements.txt (line 11)) (4.43.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio->-r requirements.txt (line 11)) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio->-r requirements.txt (line 11)) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio->-r requirements.txt (line 11)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio->-r requirements.txt (line 11)) (2023.3.post1)\n",
            "Collecting annotated-types>=0.4.0 (from pydantic>=2.0->gradio->-r requirements.txt (line 11))\n",
            "  Downloading annotated_types-0.6.0-py3-none-any.whl (12 kB)\n",
            "Collecting pydantic-core==2.10.1 (from pydantic>=2.0->gradio->-r requirements.txt (line 11))\n",
            "  Downloading pydantic_core-2.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m73.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-extensions>=4.0.0 (from pytorch-lightning->-r requirements.txt (line 5))\n",
            "  Downloading typing_extensions-4.8.0-py3-none-any.whl (31 kB)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai->-r requirements.txt (line 10)) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai->-r requirements.txt (line 10)) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai->-r requirements.txt (line 10)) (2023.7.22)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.12.0->pytorch-lightning->-r requirements.txt (line 5)) (1.12)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.12.0->pytorch-lightning->-r requirements.txt (line 5)) (2.1.0)\n",
            "Collecting colorama<0.5.0,>=0.4.3 (from typer[all]<1.0,>=0.9->gradio->-r requirements.txt (line 11))\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Collecting shellingham<2.0.0,>=1.3.0 (from typer[all]<1.0,>=0.9->gradio->-r requirements.txt (line 11))\n",
            "  Downloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
            "Requirement already satisfied: rich<14.0.0,>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer[all]<1.0,>=0.9->gradio->-r requirements.txt (line 11)) (13.6.0)\n",
            "Collecting h11>=0.8 (from uvicorn>=0.14.0->gradio->-r requirements.txt (line 11))\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<4.0.0,>=3.7.1 in /usr/local/lib/python3.10/dist-packages (from fastapi->gradio->-r requirements.txt (line 11)) (3.7.1)\n",
            "Collecting starlette<0.28.0,>=0.27.0 (from fastapi->gradio->-r requirements.txt (line 11))\n",
            "  Downloading starlette-0.27.0-py3-none-any.whl (66 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httpcore<0.19.0,>=0.18.0 (from httpx->gradio->-r requirements.txt (line 11))\n",
            "  Downloading httpcore-0.18.0-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.0/76.0 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->gradio->-r requirements.txt (line 11)) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4.0.0,>=3.7.1->fastapi->gradio->-r requirements.txt (line 11)) (1.1.3)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio->-r requirements.txt (line 11)) (2023.7.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio->-r requirements.txt (line 11)) (0.30.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio->-r requirements.txt (line 11)) (0.10.6)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio->-r requirements.txt (line 11)) (1.16.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio->-r requirements.txt (line 11)) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio->-r requirements.txt (line 11)) (2.16.1)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.12.0->pytorch-lightning->-r requirements.txt (line 5)) (1.3.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio->-r requirements.txt (line 11)) (0.1.2)\n",
            "Building wheels for collected packages: python_speech_features, pyworld, ffmpy\n",
            "  Building wheel for python_speech_features (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python_speech_features: filename=python_speech_features-0.6-py3-none-any.whl size=5870 sha256=2abfc5dcc9665e19c9e5a18393295953af8540dc77b8e6c0c0817f31bf6cab65\n",
            "  Stored in directory: /root/.cache/pip/wheels/5a/9e/68/30bad9462b3926c29e315df16b562216d12bdc215f4d240294\n",
            "  Building wheel for pyworld (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyworld: filename=pyworld-0.3.4-cp310-cp310-linux_x86_64.whl size=864156 sha256=5dcd137f1d7d7146cb4d4ce4fb771d4700914656384dd47c53602f5696b4dce8\n",
            "  Stored in directory: /root/.cache/pip/wheels/66/09/8a/a1d79b73d59756f66e9bfe55a199840efc7473adb76ddacdfd\n",
            "  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ffmpy: filename=ffmpy-0.3.1-py3-none-any.whl size=5579 sha256=665634acc2c4a5dd30ead9a7240f877bbec7dcb9d27519e11f073e2f9f3ecba6\n",
            "  Stored in directory: /root/.cache/pip/wheels/01/a6/d1/1c0828c304a4283b2c1639a09ad86f83d7c487ef34c6b4a1bf\n",
            "Successfully built python_speech_features pyworld ffmpy\n",
            "Installing collected packages: python_speech_features, pydub, ffmpy, websockets, typing-extensions, tomlkit, shellingham, semantic-version, pyworld, python-multipart, orjson, h11, colorama, annotated-types, aiofiles, uvicorn, starlette, pydantic-core, lightning-utilities, huggingface-hub, httpcore, gTTS, torchmetrics, pydantic, openai, httpx, pytorch-lightning, gradio-client, fastapi, gradio\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.5.0\n",
            "    Uninstalling typing_extensions-4.5.0:\n",
            "      Successfully uninstalled typing_extensions-4.5.0\n",
            "  Attempting uninstall: pydantic\n",
            "    Found existing installation: pydantic 1.10.13\n",
            "    Uninstalling pydantic-1.10.13:\n",
            "      Successfully uninstalled pydantic-1.10.13\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\n",
            "tensorflow-probability 0.22.0 requires typing-extensions<4.6.0, but you have typing-extensions 4.8.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed aiofiles-23.2.1 annotated-types-0.6.0 colorama-0.4.6 fastapi-0.104.1 ffmpy-0.3.1 gTTS-2.4.0 gradio-4.0.2 gradio-client-0.7.0 h11-0.14.0 httpcore-0.18.0 httpx-0.25.0 huggingface-hub-0.18.0 lightning-utilities-0.9.0 openai-0.28.1 orjson-3.9.10 pydantic-2.4.2 pydantic-core-2.10.1 pydub-0.25.1 python-multipart-0.0.6 python_speech_features-0.6 pytorch-lightning-2.1.0 pyworld-0.3.4 semantic-version-2.10.0 shellingham-1.5.4 starlette-0.27.0 tomlkit-0.12.0 torchmetrics-1.2.0 typing-extensions-4.8.0 uvicorn-0.23.2 websockets-11.0.3\n"
          ]
        }
      ],
      "source": [
        "!pip install -r requirements.txt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "nY-1T4LELlGY"
      },
      "outputs": [],
      "source": [
        "import gradio as gr"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%mkdir checkpoints"
      ],
      "metadata": {
        "id": "bgjDDXrA2lJ-"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "w-iXyNpTdpdG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50bdaf9d-cf69-4829-d0a9-99f25a294027"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/TalkingAvatar/checkpoints\n"
          ]
        }
      ],
      "source": [
        "%cd checkpoints"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZS3yLsoGoo0t",
        "outputId": "72f07d1f-50b2-40be-aa5a-2c9bf82e577f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/u/0/uc?id=1tvI43ZIrnx9Ti2TpFiEO4dK5DOwcECD7\n",
            "To: /content/TalkingAvatar/checkpoints/audio2head.pth.tar\n",
            "100% 756M/756M [00:10<00:00, 74.1MB/s]\n"
          ]
        }
      ],
      "source": [
        "!gdown https://drive.google.com/u/0/uc?id=1tvI43ZIrnx9Ti2TpFiEO4dK5DOwcECD7&export=download"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kR8r_VN8LEST",
        "outputId": "d464f26e-ee1d-4b56-da51-acd37f74b300"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/TalkingAvatar\n"
          ]
        }
      ],
      "source": [
        "%cd .."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WbZZ9oHidpdJ"
      },
      "source": [
        "# Audio to Text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "nhVm7F4DLtvQ"
      },
      "outputs": [],
      "source": [
        "from gtts import gTTS\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ZAksTjLOyqdo"
      },
      "outputs": [],
      "source": [
        "def text_to_audio(mytext : str):\n",
        "    try:\n",
        "        # Language in which you want to convert\n",
        "        language = 'en'\n",
        "\n",
        "        # Passing the text and language to the engine,\n",
        "        # here we have marked slow=False. Which tells\n",
        "        # the module that the converted audio should\n",
        "        # have a high speed\n",
        "        myobj = gTTS(text=mytext, lang=language, slow=False)\n",
        "\n",
        "        # Saving the converted audio in a mp3 file named\n",
        "        # welcome\n",
        "        myobj.save(\"audio/input.wav\")\n",
        "        return True\n",
        "    except FileNotFoundError as error:\n",
        "        print(\"Error text to audio\", error)\n",
        "        return False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mtDnabEnMrCD",
        "outputId": "5a919feb-f4fc-45ae-baed-1b8af8d8b07b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://www.google.com/imgres?imgurl=https%3A%2F%2Fpbs.twimg.com%2Fmedia%2FFjLZiZ_acAIq-lf.jpg\n",
            "To: /content/Audio2Head/imgres?imgurl=https%3A%2F%2Fpbs.twimg.com%2Fmedia%2FFjLZiZ_acAIq-lf.jpg\n",
            "\r0.00B [00:00, ?B/s]\r63.0kB [00:00, 59.8MB/s]\n"
          ]
        }
      ],
      "source": [
        "# !gdown https://www.google.com/imgres?imgurl=https%3A%2F%2Fpbs.twimg.com%2Fmedia%2FFjLZiZ_acAIq-lf.jpg&tbnid=EfmxwIQAF_UyzM&vet=12ahUKEwjaj8jdhKCCAxXmXqQEHRFgBRUQMyhCegUIARDvAQ..i&imgrefurl=https%3A%2F%2Ftwitter.com%2Faslanpahari%2Fstatus%2F1599580007067947008&docid=Ttkoa_I_Pv-rcM&w=1024&h=1024&q=ai%20generated%20images&ved=2ahUKEwjaj8jdhKCCAxXmXqQEHRFgBRUQMyhCegUIARDvAQ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bUksQ7N4dpdQ"
      },
      "source": [
        "# OpenAI Chat Module"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "JSOFlSA7z5cU"
      },
      "outputs": [],
      "source": [
        "import openai\n",
        "## if user using goole colab\n",
        "\n",
        "from google.colab import userdata\n",
        "openai.api_key = userdata.get('OPENAI_API_KEY')\n",
        "\n",
        "# openai.api_key = os.getenv('OPENAI_API_KEY') # When not running on colab\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "QR1UcODHIo7l"
      },
      "outputs": [],
      "source": [
        "def question_answer(messages):\n",
        "    response = openai.ChatCompletion.create(\n",
        "      model=\"gpt-3.5-turbo\",\n",
        "      messages=messages,\n",
        "      temperature=1,\n",
        "      max_tokens=256,\n",
        "      top_p=1,\n",
        "      frequency_penalty=0,\n",
        "      presence_penalty=0\n",
        "    )\n",
        "    return response['choices'][0]['message']['content']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "VGgLaa_UI_wZ"
      },
      "outputs": [],
      "source": [
        "messages=[\n",
        "        {\n",
        "          \"role\": \"system\",\n",
        "          \"content\": \"Answer the message enter by user.\"\n",
        "        },\n",
        "        {\n",
        "          \"role\": \"user\",\n",
        "        },\n",
        "      ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hdca7YLmJXza"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "GSk25iT2O_NL"
      },
      "outputs": [],
      "source": [
        "import subprocess"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python inference.py --audio_path audio/input.wav --img_path avatar/image.jpg"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gh4DcIp82X08",
        "outputId": "dd77afce-baee-4330-a940-4a12e8ef48cc"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ffmpeg version 4.4.2-0ubuntu0.22.04.1 Copyright (c) 2000-2021 the FFmpeg developers\n",
            "  built with gcc 11 (Ubuntu 11.2.0-19ubuntu1)\n",
            "  configuration: --prefix=/usr --extra-version=0ubuntu0.22.04.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libdav1d --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librabbitmq --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libsrt --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzimg --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-pocketsphinx --enable-librsvg --enable-libmfx --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n",
            "  libavutil      56. 70.100 / 56. 70.100\n",
            "  libavcodec     58.134.100 / 58.134.100\n",
            "  libavformat    58. 76.100 / 58. 76.100\n",
            "  libavdevice    58. 13.100 / 58. 13.100\n",
            "  libavfilter     7.110.100 /  7.110.100\n",
            "  libswscale      5.  9.100 /  5.  9.100\n",
            "  libswresample   3.  9.100 /  3.  9.100\n",
            "  libpostproc    55.  9.100 / 55.  9.100\n",
            "\u001b[0;35m[mp3 @ 0x563628404100] \u001b[0m\u001b[0;33mEstimating duration from bitrate, this may be inaccurate\n",
            "\u001b[0mInput #0, mp3, from 'audio/input.wav':\n",
            "  Duration: 00:00:02.88, start: 0.000000, bitrate: 32 kb/s\n",
            "  Stream #0:0: Audio: mp3, 24000 Hz, mono, fltp, 32 kb/s\n",
            "Stream mapping:\n",
            "  Stream #0:0 -> #0:0 (mp3 (mp3float) -> pcm_s16le (native))\n",
            "Press [q] to stop, [?] for help\n",
            "-async is forwarded to lavfi similarly to -af aresample=async=1:min_hard_comp=0.100000:first_pts=0.\n",
            "Output #0, wav, to './results/temp.wav':\n",
            "  Metadata:\n",
            "    ISFT            : Lavf58.76.100\n",
            "  Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 16000 Hz, mono, s16, 256 kb/s\n",
            "    Metadata:\n",
            "      encoder         : Lavc58.134.100 pcm_s16le\n",
            "size=       1kB time=00:00:00.00 bitrate=N/A speed=   0x    \rsize=      90kB time=00:00:02.87 bitrate= 256.3kbits/s speed= 568x    \n",
            "video:0kB audio:90kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.084635%\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/TalkingAvatar/inference.py\", line 251, in <module>\n",
            "    audio2head(parse.audio_path,parse.img_path,parse.model_path,parse.save_path)\n",
            "  File \"/content/TalkingAvatar/inference.py\", line 136, in audio2head\n",
            "    ref_pose_rot, ref_pose_trans = get_pose_from_audio(img, audio_feature, model_path)\n",
            "  File \"/content/TalkingAvatar/modules/audio2pose.py\", line 40, in get_pose_from_audio\n",
            "    ckpt_para = torch.load(model_path)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/serialization.py\", line 986, in load\n",
            "    with _open_file_like(f, 'rb') as opened_file:\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/serialization.py\", line 435, in _open_file_like\n",
            "    return _open_file(name_or_buffer, mode)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/serialization.py\", line 416, in __init__\n",
            "    super().__init__(open(name, mode))\n",
            "FileNotFoundError: [Errno 2] No such file or directory: './checkpoints/audio2head.pth.tar'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "Rr3d1Co2M99m"
      },
      "outputs": [],
      "source": [
        "def complete_data(my_text):\n",
        "    # messages[1]['content'] = text\n",
        "    # my_text = question_answer(messages)\n",
        "    print(my_text)\n",
        "    if my_text is not None:\n",
        "        check = text_to_audio(my_text)\n",
        "        if check:\n",
        "          os.system(\"rm -rf results/image_input.mp4\")  # if file already exist , delete this file\n",
        "          var = subprocess.call(\"python inference.py --audio_path audio/input.wav --img_path avatar/image.jpg\", shell = True)\n",
        "          print(var)\n",
        "          if var==0:\n",
        "            return \"results/image_input.mp4\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def respond(message, chat_history):\n",
        "    messages[1]['content'] = message\n",
        "    my_text = question_answer(messages)\n",
        "    print(my_text)\n",
        "    path = complete_data(my_text)\n",
        "    chat_history.append((message, my_text))\n",
        "    print(\"bot_message\", path)\n",
        "    return \"\", chat_history, path"
      ],
      "metadata": {
        "id": "k10iDQYs3cwH"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xozu1LYzdpdX"
      },
      "source": [
        "# Front End using Gradio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 750
        },
        "id": "YN4fIOLszdrd",
        "outputId": "07d4afdc-4d14-4ecb-8ec0-2d8cc9561149"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "Running on public URL: https://b7bc0f63f3d145e0c0.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://b7bc0f63f3d145e0c0.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello! How can I assist you today?\n",
            "Hello! How can I assist you today?\n",
            "1\n",
            "bot_message None\n",
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7861 <> https://b7bc0f63f3d145e0c0.gradio.live\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "source": [
        "with gr.Blocks() as demo:\n",
        "    with gr.Row():\n",
        "      chatbot = gr.Chatbot()\n",
        "      with gr.Column():\n",
        "        msg = gr.Textbox()\n",
        "        button = gr.Button(\"Send\")\n",
        "    with gr.Column():\n",
        "      video = gr.Video(label = \"Avatar\", autoplay = True)\n",
        "    button.click(fn = respond, inputs = [msg, chatbot], outputs = [msg, chatbot, video])\n",
        "    # msg.submit(fn = respond, inputs = [msg, chatbot], outputs = [msg, chatbot, video])\n",
        "\n",
        "demo.launch(debug = True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "xB2x6bCj1RCb",
        "outputId": "4df52094-88c2-4fa0-c134-d6b6e088e873"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2HVVVGbIdpdY"
      },
      "source": [
        "# END Have a Nice Day"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}